# -*- coding: utf-8 -*-
"""Crop Recommendation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10S2_iHpq8k8OVLkQU9fjyUgblHo8D7Ez
"""

!pip install scikit-learn pandas joblib

import pandas as pd

df = pd.read_csv("/content/crop_recommendation.csv")

df.head()

import pandas as pd
import numpy as np
import pickle
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

print("Dataset Info:")
print(df.info())

df = df.drop_duplicates()

def remove_outliers(data):
    numeric_data = data.select_dtypes(include=['number'])  # Select only numeric columns
    Q1 = numeric_data.quantile(0.25)  # 25th percentile
    Q3 = numeric_data.quantile(0.75)  # 75th percentile
    IQR = Q3 - Q1  # Interquartile Range
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    filtered_data = data[~((numeric_data < lower_bound) | (numeric_data > upper_bound)).any(axis=1)]
    return filtered_data

df_cleaned = remove_outliers(df)

print(f"Original Rows: {df.shape[0]}, Cleaned Rows: {df_cleaned.shape[0]}, Deleted: {df.shape[0] - df_cleaned.shape[0]}")

X = df_cleaned.drop(columns=['label'])  # Features
y = df_cleaned['label']  # Target variable

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

model = SVC(kernel='linear', random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy}")

print("Classification Report:\n", classification_report(y_test, y_pred))

import matplotlib.pyplot as plt
import seaborn as sns

# Boxplot for detecting outliers
plt.figure(figsize=(10,5))
sns.boxplot(data=df[['n', 'p', 'k', 'temperature', 'humidity', 'ph', 'rainfall']])
plt.show()

from sklearn.metrics import accuracy_score, classification_report

# Predict on test data
y_pred = model.predict(X_test)

# Evaluate performance
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy}")

import numpy as np

custom_input = np.array([[90, 42, 43, 20.5, 82.0, 6.5, 200]])

custom_input_scaled = scaler.transform(custom_input)

predicted_crop = model.predict(custom_input_scaled)
print("Recommended Crop:", predicted_crop[0])

test_samples = np.array([
    [100, 30, 50, 25, 100, 6.8, 250],  # Sample 1
    [70, 50, 100, 28, 85, 6.0, 300],   # Sample 2
])

# Scale input features
test_samples_scaled = scaler.transform(test_samples)

# Predict crops
predictions = model.predict(test_samples_scaled)
print("Predicted Crops:", predictions)

import pickle

# Save the trained model
with open("/content/crop_recommender.pkl", "wb") as file:
    pickle.dump(model, file)

# Save the scaler (needed for future predictions)
with open("/content/scaler.pkl", "wb") as file:
    pickle.dump(scaler, file)

print("Model and scaler saved successfully!")